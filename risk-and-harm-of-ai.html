<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ali Run Ads - Paid Ads Expert</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
<nav class="navbar">
        <div class="navbar-container container">
            <input type="checkbox" name="" id="">
            <div class="hamburger-lines">
                <span class="line line1"></span>
                <span class="line line2"></span>
                <span class="line line3"></span>
            </div>
            <ul class="menu-items">
                <li><a href="https://alirunads.com">Home</a></li>
                <li><a href="./services.html">Services</a></li>
                <li><a href="./toolkit.html">Toolkit</a></li>
                <li><a traget="_blank" href="https://www.youtube.com/@alirunads">Videos</a></li>
                <li><a href="./blog.html">Blog</a></li>
                <li><a href="./contact.html">Contact</a></li>
            </ul>
            <h1 class="logo"><img width="150px;" src="./assets/logo.png" /></h1>
        </div>
    </nav>
<main class="wp-block-group is-layout-flow" style="margin-top:var(--wp--preset--spacing--50)" id="wp--skip-link--target">
<div class="wp-block-group is-layout-flow"><h2 class="has-text-align-center wp-block-post-title">Risk &amp; Harm of A.I.</h2>

<div class="entry-content wp-block-post-content is-layout-flow"><div class="has-text-align-center wp-block-post-date"><time datetime="Updated 2023-06-04T03:23:21+00:00">Updated June 4, 2023</time></div>


<div class="wp-block-group has-global-padding is-layout-constrained wp-container-8">
<p>The Godfather of AI(<strong><a href="https://www.cs.toronto.edu/~hinton/" data-type="URL" data-id="https://www.cs.toronto.edu/~hinton/" target="_blank" rel="noreferrer noopener">Dr. Hinton</a></strong>) leaves Google &amp; regrets his life’s work. He warns risks &amp; dangers of A.I. ahead.</p>



<p>Let’s explore the tech experts’ perceptions &amp; thoughts on A.I. technology.</p>



<div class="wp-block-group has-basewhite-color has-tertiarygreen-background-color has-text-color has-background has-medium-font-size has-global-padding is-layout-constrained wp-container-6" style="border-style:none;border-width:0px;border-radius:13px;padding-top:var(--wp--preset--spacing--30);padding-right:var(--wp--preset--spacing--30);padding-bottom:var(--wp--preset--spacing--30);padding-left:var(--wp--preset--spacing--30)">
<p><strong>The short answer is</strong>: While we are seeing many wonderful uses for artificial intelligence, tech giants are also seeing more harm than good for humanity. It’s obvious that tech firms are confused of how to address the risks and harms associated with artificial intelligence.</p>
</div>



<h2 class="wp-block-heading">Experts on A.I.(Artificial Intelligence) Risks &amp; Harms</h2>



<h3 class="wp-block-heading">Table of contents:</h3>



<ol>
<li><a href="#hinton" data-type="internal" data-id="#hinton">Dr. Geoffrey Hinton</a></li>



<li><a href="#jeff-dean" data-type="internal" data-id="#jeff-dean">Jeff Dean</a></li>



<li><a href="#sundar-pichai" data-type="internal" data-id="#sundar-pichai">Sundar Pichai</a></li>



<li><a href="#others" data-type="internal" data-id="#others">Others</a></li>



<li><a href="#conclusion" data-type="internal" data-id="#conclusion">Conclusion</a></li>
</ol>



<h4 class="wp-block-heading" id="hinton"><strong><a href="https://en.wikipedia.org/wiki/Geoffrey_Hinton">1. Dr. Geoffrey </a><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Geoffrey_Hinton" target="_blank">Hinton</a></strong></h4>



<p>Hinton&nbsp;<a rel="noreferrer noopener" href="https://twitter.com/geoffreyhinton/status/1652993570721210372" target="_blank">tweeted</a>&nbsp;on Monday <time datetime="2023-05-01T11:09:13.000Z">May 1, 2023</time>, “I left so that I could talk about the dangers of AI without considering how this impacts Google. Google has acted very responsibly.”</p>



<p>The <strong><em>New York Times</em></strong> published an article on May 1, 2023 “The Godfather of A.I.’ Leaves Google &amp; Warn of Danger Ahead.”</p>



<p>Dr. Hinton embraced the concept of a neural network in 1972 as a graduate student at the University of Edinburgh. A neural network is a mathematical system that gains skills by analyzing data. Few scientists at the time accepted the theory.<br>However, he made it the focus of his life.</p>



<p>Dr. Hinton and two of his students from Toronto, Ilya Sutskever and Alex Krishevsky, developed a neural network in 2012 that could examine hundreds of photographs and train itself to recognize common objects like cars, pets, and flowers.</p>



<p>Google invested $44 million to purchase a business that Dr. Hinton and his two students founded. And as a result of their system, more potent technologies were developed, such as <a href="https://openai.com/blog/chatgpt" target="_blank" rel="noreferrer noopener">ChatGPT</a> and <a href="https://bard.google.com/" target="_blank" rel="noreferrer noopener">Google Bard</a>, new chatbots.</p>



<p>Dr. Hinton said he has quit his job at Google, where he has worked for more than a decade and became one of the most respected voices in the field, so he can freely speak out about the risks of A.I. A part of him, he said, <strong><em>now regrets his life’s work</em></strong>.</p>



<p>Dr. Hinton said in a lengthy interview, “I console myself with the usual excuse: If I hadn’t done it, somebody else would have.”</p>



<p>Industry leaders predict that the new A.I. systems could have the same impact as the early 1990s launch of the web browser and result in advancements in everything from drug research to education.</p>



<p>But many business insiders are plagued by a worry that they are discharging something hazardous into the wild. Already, generative AI has the potential to spread false information. It might soon endanger jobs. The largest skeptics of technology claim that at some point in the future, there may be a risk to humanity.</p>



<p>Dr. Hinton made reference to “bad actors” who would try to exploit AI for “bad things” in the article published by the New York Times.</p>



<p>In response to a question from the <strong>BBC</strong> asking him to elaborate, he said: “This is simply kind of a worst-case scenario, kind of a nightmare scenario.</p>



<p>“You can imagine, for example, that some bad actor like [Russian President Vladimir] Putin decided to give robots the ability to create their own sub-goals.”</p>



<p>In March, an open letter – co-signed by dozens of people in the AI ​​field, including tech billionaire Elon Musk – called for a halt to any more advanced development than the current version of the AI ​​ChatGPT chatbot to take remedial action. Powerful safety devices can be designed. and do.&nbsp;</p>



<p>Dr Hinton, often referred to as the “godfather of AI”, did not sign any of these letters and said he did not want to publicly criticize Google or<br>other businesses until he quits.&nbsp;</p>



<p>Dr. Hinton strongly opposes the use of artificial intelligence on the battlefield – what he calls “robot soldiers”.&nbsp;</p>



<p>The tech giants are locked in a competition that might be impossible to stop, Dr. Hinton said.</p>



<p>His immediate concern on ChatGPT/Bard is that the internet will be flooded with fake photographs, videos, and text, and that the typical person will <strong>“no longer be able to know what is true anymore.”</strong></p>



<p>He is also concerned that artificial intelligence technology would eventually upend the job economy. Chatbots like ChatGPT currently supplement human labor, but they could eventually replace paralegals, personal assistants, translators, and others who perform repetitive jobs. “It takes away the drudge work,” he explained. “It might take away more than that.”</p>



<p>Dr. Hinton thinks that without some type of global control, the competition between Google, Microsoft, and others will intensify into a race that will never end.<br>But he added that might not be doable. He claimed that, unlike nuclear weapons, it is impossible to tell whether businesses or nations are secretly developing the technology. The best chance is for the top scientists in the world to work together on approaches to managing the technology.<br>I don’t think they should scale this up more, he remarked, before they know if they can control it.</p>



<p>“Any digital data you see – audio or video – you have to entertain the idea that someone has spoofed it.”</p>



<p>He told the BBC that some of the risks of AI chatbots were “quite frightening.”</p>



<p>The kind of intelligence we’re producing, he continued, “is completely different from the intelligence we already have.</p>



<p>Although they are digital systems, we are biological systems. The main distinction is that with digital systems, the same set of weights and world model are duplicated widely.</p>



<p>“And each of these clones can learn independently and quickly communicate what they learn. As a result, it is as if there were 10,000 chatbots and that when one chatbot learned something, everyone else knew it too. This is how these chatbots are able to know so much more than a single person.</p>



<p>However, Dr. Hinton told the BBC that “in the shorter term” he believed that risks from AI would be greatly outweighed by benefits. “So I don’t think we should stop developing this stuff,” he added.</p>



<p>He added that it would be challenging to take a break due to worldwide competitiveness. Even if everyone in the US stopped working on it, China would still have a significant advantage, he claimed.</p>



<p>Dr. Hinton said that he was a scientist, not a politician, and that it was the government’s job to make sure AI was built “with a lot of thought into how to stop it going rogue.”</p>



<p>It is important to remember that AI chatbots are just one aspect of artificial intelligence, even if they are the most popular right now.</p>



<p>The algorithms used by video streaming services to determine what you should watch next are powered by AI. It is able to diagnose medical issues, while human doctors still have the final say, and is used in insurance premium calculation and recruitment to screen job applications.</p>



<p>When people used to ask Dr. Hinton how he could work on potentially hazardous technology, he would quote Robert Oppenheimer, who oversaw the United States’ campaign to develop the atomic bomb: “<strong>When you see something that is technically sweet, you go ahead and do it</strong>.”</p>



<p>Don’t get me wrong, we’re sitting on a speeding train right now, but the worry is that one day the train will start building its own tracks.&nbsp;</p>



<div class="wp-block-group has-basewhite-color has-text-color has-background has-global-padding is-layout-constrained" style="background:linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 4%,rgb(107,0,62) 100%);padding-top:var(--wp--preset--spacing--30);padding-right:var(--wp--preset--spacing--30);padding-bottom:var(--wp--preset--spacing--30);padding-left:var(--wp--preset--spacing--30)">
<p>From Dr. Hinton, we can conclude some key points regarding the negative impacts of A.I. technologies:</p>



<ul>
<li>A flood of  false &amp; misinformation on the internet</li>



<li>Creates doubts on testimony of people on the internet</li>



<li>Very difficult for a layman or average person to distinguish between  truth &amp; falsehood</li>



<li>Risk to humanity</li>



<li>Robotics soldiers on battlefield</li>



<li>Risk of jobs especially repetitive jobs</li>



<li>Lack of control, rules &amp; regulation on the internet</li>
</ul>
</div>



<h4 class="wp-block-heading" id="jeff-dean"><a href="https://en.wikipedia.org/wiki/Jeff_Dean" data-type="URL" data-id="https://en.wikipedia.org/wiki/Jeff_Dean" target="_blank" rel="noreferrer noopener">2. Jeff Dean</a></h4>



<p> Jeff Dean (Google’s Chief Scientist) said in a statement: “We remain committed to a responsible approach to A.I. We’re continually learning to understand emerging risks while also innovating boldly.”</p>



<h4 class="wp-block-heading" id="sundar-pichai"><a href="https://en.wikipedia.org/wiki/Sundar_Pichai" data-type="URL" data-id="https://en.wikipedia.org/wiki/Sundar_Pichai" target="_blank" rel="noreferrer noopener">3. Sundar Pichai</a></h4>



<p>Even Google CEO Sundar Pichai admitted recently that he didn’t fully comprehend all that Bard, the company’s AI chatbot, did.</p>



<h4 class="wp-block-heading" id="others">4. Others</h4>



<p>#1 – A hasty approach to safety in AI systems would not be accepted in any other field, according to <strong><em>Valérie Pisano, CEO of Mila, the Quebec Artificial Intelligence Institute</em></strong>. The technology is made available, and when it interacts with people, its creators watch to observe what happens and make changes in response to that. Collectively, we would never permit this way of thinking in any other sector of industry. There’s something about social media and technology that makes us think, “Yeah, sure, we’ll figure it out later,” she added.</p>



<p>#2 – People should be skeptical of any online media they encounter today, according to <strong><em>Toby Walsh, the director of the University of New South Wales AI Institute</em></strong>.</p>



<p>#3 – Speaking in his own role to the BBC, <strong><em>Matt Clifford</em></strong>, the chairman of the UK’s Advanced Research and Invention Agency, said that Dr. Hinton’s statement “underlines the rate at which AI capabilities are accelerating.”</p>



<h2 class="wp-block-heading" id="conclusion">Conclusion</h2>



<p>The expression of worries and cautions regarding artificial intelligence (AI) by professionals and researchers, however, is not unusual. Elon Musk and Stephen Hawking are two well-known experts who have brought attention to the dangers that could come with using highly developed AI systems. <strong>Approaching AI development cautiously is vital, making sure that the right moral standards and security precautions are in place to minimize any bad effects.</strong></p>
</div>
</div>


<hr class="wp-block-separator has-text-color has-alpha-channel-opacity has-background" style="background-color:#bdc6cb;color:#bdc6cb">
</div>
</main>
</body></html>